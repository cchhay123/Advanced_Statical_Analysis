---
title: "Homework 2: Data Partition and Backward Selection"
author: "Chamroeun Chhay"
output: html_document
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

There are six questions (30 total points) in this assignment. The
minimum increment is 1 point. Please type in your answers directly in
the R Markdown file. After completion, **successfully** knitr it as an
html file. Submit [**both**]{style="color:red"} the html file and the R
Markdown file via Canvas. Please name the R Markdown file in the
following format: LastName_FirstName_HW2.Rmd, e.g. Zhao_Zifeng_HW2.Rmd.

## Used Car Dataset [12 points]

The used car dataset is the one we analyzed in class. Let's read in the
data stored in `UsedCar.csv` and further partition the data into
training and test data. Note that we use the same random seed
`set.seed(7)` as in class to ensure reproducibility.

```{r chunk1}
total_data <- read.csv("./UsedCar.csv", header=T, stringsAsFactors=T)
set.seed(7)
total_obs <- dim(total_data)[1]
# Data partition / Sample splitting
train_data_indices <- sample(1:total_obs, 0.8*total_obs)
train_data <- total_data[train_data_indices,]
test_data <- total_data[-train_data_indices,]
# Record the size of training data and test data
train_obs <- dim(train_data)[1]
```

### **Q1 [3 points]** Model Estimation

Instead of building linear regression models on the log-scale Price,
let's build linear regression models for the original scale of Price,
i.e. without log transformation to correct the right-skewness of Price.

**Q1(a) [2 points]** Fit a linear regression model of **original scale**
Price w.r.t. all 10 predictors using the **training data**, name it
`lm_full`.

```{r Q1(a)}
lm_full <- lm(Price ~., data = train_data)
```

**Q1(b) [1 points]** Check the estimated coefficient for `Mileage`, how
do we interpret it?

```{r Q1(b)}
summary(lm_full)
lm_full$coefficients

```

Answer: The coefficient of the Mileage in the linear regression model is -1.669933e-02. This means that the price of the used car will decrease by -1.669933e-02 for every unit increase in mileage. 

### **Q2 [4 points]** Backward Selection with BIC

**Q2(a) [2 points]** Perform backward selection for `lm_full` with
**BIC** using the function `step()` and name the selected model
`lm_bwd`. Make sure you use the correct **`k`** argument in the `step()`
function.

```{r Q2(a)}
lm_bwd <- step(lm_full, direction = 'backward', k = log(train_obs))

```

**Q2(b) [2 points]** Examine the selected model in `lm_bwd`, list all
the predictors that are eliminated during the backward selection
process.

```{r Q2(b)}
summary(lm_bwd)
```

Answer: The predictors that were eliminated during the backward selection process are CC, Metallic, Doors, Automatics. 

### **Q3 [5 points]** Model Evaluation (Prediction)

**Q3(a) [2 points]** Use `lm_full` and `lm_bwd` to generate predictions
for Price on the test data and store the prediction in `lm_full_pred`
and `lm_bwd_pred` respectively.

```{r Q3(a)}
lm_full_pred <- predict(lm_full, newdata = test_data)
lm_bwd_pred <- predict(lm_bwd, newdata = test_data)

```

**Q3(b) [2 points]** Use the `R` package `forecast` to evaluate the
prediction performance of `lm_full_pred` and `lm_bwd_pred`. What are the
MAE for `lm_full` and `lm_bwd`?

```{r Q3(b)}
library(forecast)
accuracy(lm_full_pred, test_data$Price)
accuracy(lm_bwd_pred, test_data$Price)
```

Answer: The MAE for `lm_full` and `lm_bwd` are 1058.757 and 1069.966 respectively. 

**Q3(c) [1 points]** Recall from the in-class exercise that the MAE made
by `lm_full` with log-transformation are `950.0841`. Compare with the
MAE made by `lm_full` in Q3(b) without log-transformation. Does
log-transformation help improve out-of-sample prediction performance?

Answer: The log-transformation does help improve out of sample prediction performance, but the difference between the two errors is not too significant.

## Car Seat Sales Dataset [18 points]

The car seat sales dataset is the one we analyzed in HW1. It contains
sales of child car seats at 400 different stores and the data is stored
in `Carseats.csv`. It contains 9 variables, `Sales`, `CompPrice`,
`Income`, `Advertising`, `Population`, `Price`, `ShelveLoc`, `Age` and
`Urban`. We would like to build a linear regression model to predict
`Sales` at a planned new store. The data description is as follows.

-   `Sales`: Unit sales (in thousands) at each location
-   `CompPrice`: Price charged by competitor at each location
-   `Income`: Community income level (in thousands of dollars)
-   `Advertising`: Local advertising budget for company at each location
    (in thousands of dollars)
-   `Population`: Population size in region (in thousands)
-   `Price`: Price company charges for car seats at each site
-   `ShelveLoc`: A factor with levels Bad, Good and Medium indicating
    the quality of the shelving location for the car seats at each site
-   `Age`: Average age of the local population
-   `Urban`: A factor with levels No and Yes to indicate whether the
    store is in an urban or rural location

### **Q4 [5 points]** Data Partition

**Q4(a) [2 points]** Let's correctly read in the data in `Carseats.csv`
and name it as `total_data`.

```{r Q4(a)}
total_data <- read.csv("./Carseats.csv", header=T, stringsAsFactors=T)

```

**Q4(b) [3 points]** Let's partition the data in `total_data` into
training **(80%)** and test data **(20%)** and store them as `R` objects
`train_data` and `test_data` respectively. Use random seed
**`set.seed(7)`**!

```{r Q4(b)}
set.seed(7)
total_obs <- dim(total_data)[1]
train_data_indices <- sample(1:total_obs, 0.8*total_obs)
train_data <- total_data[train_data_indices,]
test_data <- total_data[-train_data_indices,]
train_obs <- dim(train_data)[1]
```

### **Q5 [8 points]** Model Estimation and Backward Selection

**Q5(a) [2 points]** Fit a linear regression model of **original scale**
Sales w.r.t. all 8 predictors using the **training data**, name it
`lm_full`.

```{r Q5(a)}
lm_full <- lm(Sales ~., data = train_data)
summary(lm_full)
```

**Q5(b) [2 points]** Perform backward selection for `lm_full` with
**BIC** using the function `step()` and name the selected model
`lm_bwd`. Make sure you use the correct **`k`** argument in the `step()`
function.

```{r Q5(b)}
lm_bwd <- step(lm_full, direction = 'backward', k = log(train_obs))
```

**Q5(c) [2 points]** Examine the printout of the `step()` function in
Q5(b), what is the first predictor removed in the backward selection?

Answer: The first predictor removed in the backward selection is Population. 

**Q5(d) [2 points]** Examine the selected model in `lm_bwd`, list all
the predictors that are eliminated during the backward selection
process.

```{r Q5(c)}
summary(lm_bwd)
```

Answer: The predictors that were eliminated during the backward selection process are Population and Urban. 

### **Q6 [5 points]** Model Evaluation (Prediction)

**Q6(a) [2 points]** Use `lm_full` and `lm_bwd` to generate predictions
for Sales on the test data and store the prediction in `lm_full_pred`
and `lm_bwd_pred` respectively.

```{r Q6(a)}
lm_full_pred <- predict(lm_full, newdata = test_data)
lm_bwd_pred <- predict(lm_bwd, newdata = test_data)

```

**Q6(b) [2 points]** Use the `R` package `forecast` to evaluate the
prediction performance of `lm_full_pred` and `lm_bwd_pred`. What are the
MAE for `lm_full` and `lm_bwd`?

```{r Q6(b)}
library(forecast)
accuracy(lm_full_pred, test_data$Sales)
accuracy(lm_bwd_pred, test_data$Sales)

```

Answer: The MAE for lm_full_pred and lm_bwd_pred are 0.8582053 and 0.8597975 respectively. 

**Q6(c) [1 points]** Which statistical model do you prefer, `lm_full` or
`lm_bwd`? Give reasons.

Answer: I would prefer using `lm_bwd` model. Even though the MAE in `lm_bwd` is greater then `lm_full`, the difference is small enough that it would not change much. `lm_bwd` is the simpler model with two less predictors. It would make future prediction less dependent on so many predictors. 
